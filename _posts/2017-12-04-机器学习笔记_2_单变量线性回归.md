---
title: 机器学习笔记_2_单变量线性回归
date: 2017-12-04 22:00:00
categories: 机器学习笔记
tags: 机器学习 监督算法 无监督算法
---

***

*吴恩达机器学习课程_个人笔记*

*课程来源：[https://www.bilibili.com/video/av9912938](https://www.bilibili.com/video/av9912938)*

***

***

2 Linear Regression with one variable

***

# 2-1 Model Representation模型表示
以上述预测房价为例
线性回归 hθx=θ0+θ1x
<div align=center> <img src="https://weidi1024.github.io/images/jiqixuexi.2.1.png" height="20%" /> </div>
# 2-2 Cost Function代价函数
代价函数也称误差函数
# 2-3 Cost Function - Intuition I
举例说明代价函数的计算方法：简单的，当θ0=0时；代价函数只有一个参数。
# 2-4 Cost Function - Intuition II
举例说明代价函数。代价函数有两个参数。曲面图。

我们需要一个算法，来寻找使得代价函数最小的参数θ0和θ1。
# 2–5 Gradient Descent梯度下降算法
Learning Rate 相当于步长，下山每一步的长度。
同时更新Simultaneous update所有参数（此处是0和1）。
 
# 2-6 Gradient Descent Intuition
1举例说明 当只有一个参数
2当学习率（步长）取得太小，下降速率就太慢；学习率太大，下降速率太快，有可能跳出最优解，也有可能发散。
当接近局部最优解时，梯度（导数）越来越小，梯度下降的步长（减去项）越来越小，因此没有必要手动减小学习率。
# 2–7  Gradient Descent For Linear Regression线性回归中的梯度下降
将梯度下降算法应用到线性回归中，并举例说明。