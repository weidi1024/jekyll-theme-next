---
title: Faster R-CNN阅读
date: 2019-07-23 22:00:00
categories: Object_Detection
tags: Object_Detection Faster_R-CNN
mathjax: false
---

**重拾Faster R-CNN**   
之前阅读过这篇文章，但是阅读的比较泛，也没有很好地去记录，最近需要用到Faster R-CNN，就想着再次阅读一次，主要是简单的翻译和总结，一来可以加深对文章某些细节的理解，二来可以做一些记录，方便以后查阅。


**文章地址：**    
地址1：arxiv：[Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks](https://arxiv.org/abs/1506.01497)   
地址2：nips：[Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks](http://papers.nips.cc/paper/5638-faster-r-cnn-towards-real-time-object-detection-with-region-proposal-networks.pdf)
代码：[https://github.com/rbgirshick/py-faster-rcnn](https://github.com/rbgirshick/py-faster-rcnn)

# 摘要
先进的目标检测算法依赖于区域提取算法来假设目标的位置。SPPNet和Fast R-CNN等先进的算法降低了检测网络的运行时间，但是区域提取部分的计算也是一个瓶颈。本文中，我们提出了一个与检测网络共享卷积特征的区域提取网络(Region Proposal Network，RPN)，使得几乎无代价的区域提取成为可能。RPN是一个全卷积网络，同时预测每个位置的目标位置和置信度。RPN可以端到端的训练，可以产生高质量的候选区域，用来给Fast R-CNN进行检测。通过共享RPN和Fast R-CNN的基础网络，我们将这两个网络合并成一个统一的网络，使用最近流行的“注意力”机制，RPN告诉网络在何处寻找目标。对于使用VGG-16作为基础网络，我们的检测系统在GPU上的帧率为5fps，同时在PASCAL VOC 2007, 2012, and MS COCO数据集上获得了最先进的目标检测精度，我们的RPN网络仅仅提供300个候选区域。在ILSVRC和COCO 2015的比赛中，Faster R-CNN和RPN是在几个轨道上获得第一名的基础。代码已经公开。

# 1 引言
**这部分简读**    
      基于区域建议的方法的瓶颈：区域建议的方法和基于区域提取的CNN推动了目标检测领域的发展。现在区域提取部分是测试阶段的速度瓶颈。   
一种解决方法：把算法从CPU迁移导致GPU上，但是这样做会忽略了对网络底层的特征的利用，错过了共享参数的机会。   
本文的方法：本文中，我们证明了基于深度卷积神经网络的区域提取方法是一个很好的解决方案，相对于检测网络的运行时间，其运行时间几乎是可以忽略的。区域提取的成本很小，10ms每幅图。   
共享卷积特征的可能性：可以在卷积特征图上加入了模块进行区域提取，不影响原来的结构。可以根据区域建议任务进行端到端的训练。   
RPN的优点：RPN的设计是为了广泛提取具有不同尺寸和纵横比的候选区域，与常用的方法[8], [9], [1], [2]不同，它们使用图像金字塔或者滤波器金字塔等策略，我们引入了新的“anchor”框，可以作为多种尺度和纵横比的参考。我们的方案可以被认为是a pyramid of regression references，它避免了枚举多个尺度或纵横比的图像或过滤器。当使用单尺度图像进行训练和测试时，该模型性能良好，提高了运行速度。    
训练策略：为了将RPN与Fast R-CNN统一起来，我们设计了一种训练方法，交替对RPN和Fast R-CNN进行微调，这种方法收敛速度快，可以让RPN与Fast R-CNN共享基础网络。     
实验结果优秀：PASCAL VOC的结果精度和速度都最好。第一版文章发布后，基于RPN和Faster R-CNN，出现了很多优秀的算法，如3D object detection [13], part-based detection [14], instance segmentation [15], and image captioning [16]。其他比赛中也取得了优异的性能。这些结果表明，我们的方法不仅速度快，而且精度高。

# 2 相关工作
**这部分简读**    
**候选目标区域Object Proposals**   
关于候选目标区域有大量的文献资料，可以参考这几篇综述[19], [20], [21].广泛使用的候选区域提取方法基于grouping super-pixels (e.g., Selective Search [4], CPMC [22], MCG [23]) and sliding windows(e.g., objectness in windows [24], EdgeBoxes [6]).的方法。候选目标区域的方法作为独立于检测器的外部模块，比如选择性搜索（Selective Search）检测器，R-CNN和Fast R-CNN。   
**基于深度网络的目标检测**   
R-CNN的方法端到端地训练CNN，将候选区域分为目标或者背景类别。R-CNN主要作为一个分类器，不进行候选区域的预测，除了对边框进行精细回归。有文章[20]说明，它的性能主要取决于候选区域模块的性能。目前已经有一些文章[25], [9], [26], [27]使用深度网络来预测候选区域。在OverFeat[9]中，使用全连接层来为定位任务预测边框，假定图像中只有一个目标。全连接层后来转变成卷积层用来检测多类目标。在MultiBox方法[26],[27]中，通过网络最后一层全连接层同时预测多个类无关的候选边框，推广了OverFeat中的单一边框的方法。这些类别无关的边框可以被用作R-CNN的候选区域。DeepMask method [28] 也是基于我们的方法。   
共享卷积计算因其高效和高性能，在视觉识别领域受到了越来越广泛的关注。OverFeat使用图像金字塔进行检测。SPPNet中在共享的特征图上进行自适应的池化。


# 3 Faster R-CNN
我们的目标检测器称为Faster R-CNN，分为两个该部分。第一部分是全卷积网络，用来生成候选区域，第二部分是Fast R-CNN检测器。整个网络是一个独立统一的结构。3.1我们介绍RPN的设计和特性，3.2介绍训练共享卷积特征的两部分的训练算法。

**3.1 RPN**   
RPN将整个图像输入网络，输出一系列矩形候选区域，以及它们的置信度。我们使用一个全卷积网络来实现这个过程。因为我们最终要将RPN与Fast R-CNN共享计算，因此我们假定两个网络共享一些卷积层。实验中，我们采用ZF Net作为基础网络，共享5个卷积层；使用VGG作为基础网络，共享13个卷积层。   
为了生成候选区域，我们在最后一个卷积层输出的特征图上滑动一个小的网络，这个小网络将nxn大小的窗口作为输入的卷积特征图。通过小网络，每一个滑动窗口的特征都映射到一个低维的特征，每个特征被送入两个滑动的全连接层，一个边框回归层和一个边框分类层。考虑到这一层对应于输入图像的感受野较大，我们将n设置为3。图3表示了这个小网络的位置。因为这个小网络的计算是滑窗进行的，全连接层在不同位置上是共享的，所以这部分网络是通过一个nxn的卷积层和两个1x1的卷积层实现的。

**3.1.1 Anchors**   
在每一个滑窗位置，我们同时预测多个候选区域，我们将每个位置最大可能的候选区域个数设置为k。因此回归层的输出节点数为4k，编码k个区域的位置；分类层的输出节点数为2k，用来预测每个候选区域是否为目标类。k个候选区域对应k个预选框，我们称之为anchor。anchor是以滑动窗口为中心，并且与一个尺寸和纵横比关联。我们默认设置了3个不同的尺寸和3个不同的纵横比，这样会在每个滑动窗口位置产生k=9个anchor。假设特征图的尺寸为WxH，那总共有WxHxk个anchor。   
* **Translation-Invariant Anchors**   
平移不变的anchor    
我们的方法的一个重要特性是平移不变性，包括anchor的计算和候选区域计算的相关函数。如果输入图像中的一个目标被移动了，那么候选区域也应该平移，相同的函数应该能计算不同位置的候选区域。相比之下，MultiBox方法使用k-means产生800个左右的候选区域，并不是具有平移不变性的。   
平移不变性也减少了网络的参数量。MultiBox具有(4+1)*800维度的全连接层输出层，我们的方法只需要(4+2)*9维度的卷积输出层。在网络参数量方面，我们的方法也具有。如果考虑到特征投影层，我们的方法依然比MultiBox方法的参数量少一个数量级。   
* **Multi-Scale Anchors as Regression References**   
多尺度anchors作为回归参考   
我们anchors的设计提出了一种新颖的解决多尺度和多纵横比的方案。如图1所示，多尺度预测主要有两种解决方案。第一种是基于图像/特征金字塔，比如 DPM [8] 和基于CNN的方法 [9], [1], [2]，这种方法将图像resize到不同的尺寸，通过网络得到不同尺寸的特征图，这种方法有效，但是十分耗时。第二种是在特征图上使用不同尺寸或者纵横比的窗口滑窗，不同尺寸的窗口分别使用不同尺寸的滤波器进行训练，这种可以理解成金字塔滤波器。第二种方法通常与第一种方法联合使用。    
与前面的方法不同，我们的方法建立在一个金字塔anchor上，在代价上更具有高效性。我们的方法参照多个尺度和纵横比的锚框对边界框进行分类和回归。只依赖一个尺度的输入图像和一个尺寸特征图，并且使用单一尺寸的滤波器。我们的实验结果说明了对多尺度问题的处理效果。   

**3.1.2 Loss Function**   



**3.1.3  Training RPNs**   


**3.2 RPN与Fast R-CNN共享特征**  


**3.3 实施细节**  

# 4 实验
实验部分后续有时间再看

# 5 结论